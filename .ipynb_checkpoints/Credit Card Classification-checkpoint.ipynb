{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification on Credit Card Application data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter Notebook, I will perform data cleaning and transformation on confidential credit card application data to classify the unknown data. I will specifically look at a certain attribute in the data, *A16*, being \"+\" by creating linear and logistic regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# warning code taken from \n",
    "# https://stackoverflow.com/questions/40659212/futurewarning-elementwise-comparison-failed-returning-scalar-but-in-the-futur\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import sklearn.linear_model as slm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00202</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1     A2     A3 A4 A5 A6 A7    A8 A9 A10  A11 A12 A13    A14  A15 A16\n",
       "0  b  30.83  0.000  u  g  w  v  1.25  t   t    1   f   g  00202    0   +\n",
       "1  a  58.67  4.460  u  g  q  h  3.04  t   t    6   f   g  00043  560   +\n",
       "2  a  24.50  0.500  u  g  q  h  1.50  t   f    0   f   g  00280  824   +\n",
       "3  b  27.83  1.540  u  g  w  v  3.75  t   t    5   t   g  00100    3   +\n",
       "4  b  20.17  5.625  u  g  w  v  1.71  t   f    0   f   s  00120    0   +"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data.\n",
    "credit = pd.read_csv(\"data/credit-card-applications.csv.bz2\")\n",
    "credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(690, 16)\n"
     ]
    }
   ],
   "source": [
    "# Check dataframe dimensions.\n",
    "print(credit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1     12\n",
      "A2     12\n",
      "A3      0\n",
      "A4      6\n",
      "A5      6\n",
      "A6      9\n",
      "A7      9\n",
      "A8      0\n",
      "A9      0\n",
      "A10     0\n",
      "A11     0\n",
      "A12     0\n",
      "A13     0\n",
      "A14    13\n",
      "A15     0\n",
      "A16     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values.\n",
    "credit = credit.replace('?', np.nan)\n",
    "missings = credit.isna().sum()\n",
    "print(missings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is about credit card applications that has 690 rows of information for 16 variables. I found that there were NA values in the form of a `?`, but per the associated metadata, 37 cases (5%) have one or more missing values.The meaningless variables names of A1-A16 and symbols inside each variable were utilized to protect user information and confidentiality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1      object\n",
      "A2      object\n",
      "A3     float64\n",
      "A4      object\n",
      "A5      object\n",
      "A6      object\n",
      "A7      object\n",
      "A8     float64\n",
      "A9      object\n",
      "A10     object\n",
      "A11      int64\n",
      "A12     object\n",
      "A13     object\n",
      "A14     object\n",
      "A15      int64\n",
      "A16     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Ensure the variables are of appropriate type.\n",
    "print(credit.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the dataset contains a mixture of variable types including `object`, `float64`, and `int64`. This is as expected because Strings are objects, and the variables with decimial points being `A3` and `A8` are considered floats. The numeric variables would be `A11` and `A15` which is indeed of appropriate int type after checking. `A9`, `A10`, `A12` seem to be boolean type but is considered object type because the content includes shorthanded names such as `t` and `f`, which likely stands for `true` and `false`, respectively. I was surprised that `A2` was considered an object, even though it contained decimal points and looks like a float. It likely wasn't considered a float because it only had 2 decimial points, and therefore got classified as an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1: ['b' 'a' nan] A4: ['u' 'y' nan 'l'] A5 ['g' 'p' nan 'gg'] A6: ['w' 'q' 'm' 'r' 'cc' 'k' 'c' 'd' 'x' 'i' 'e' 'aa' 'ff' 'j' nan] A7: ['v' 'h' 'bb' 'ff' 'j' 'z' nan 'o' 'dd' 'n'] A9: ['t' 'f'] A10: ['t' 'f'] A12: ['f' 't'] A13: ['g' 's' 'p'] A14: ['00202' '00043' '00280' '00100' '00120' '00360' '00164' '00080' '00180'\n",
      " '00052' '00128' '00260' '00000' '00320' '00396' '00096' '00200' '00300'\n",
      " '00145' '00500' '00168' '00434' '00583' '00030' '00240' '00070' '00455'\n",
      " '00311' '00216' '00491' '00400' '00239' '00160' '00711' '00250' '00520'\n",
      " '00515' '00420' nan '00980' '00443' '00140' '00094' '00368' '00288'\n",
      " '00928' '00188' '00112' '00171' '00268' '00167' '00075' '00152' '00176'\n",
      " '00329' '00212' '00410' '00274' '00375' '00408' '00350' '00204' '00040'\n",
      " '00181' '00399' '00440' '00093' '00060' '00395' '00393' '00021' '00029'\n",
      " '00102' '00431' '00370' '00024' '00020' '00129' '00510' '00195' '00144'\n",
      " '00380' '00049' '00050' '00381' '00150' '00117' '00056' '00211' '00230'\n",
      " '00156' '00022' '00228' '00519' '00253' '00487' '00220' '00088' '00073'\n",
      " '00121' '00470' '00136' '00132' '00292' '00154' '00272' '00340' '00108'\n",
      " '00720' '00450' '00232' '00170' '01160' '00411' '00460' '00348' '00480'\n",
      " '00640' '00372' '00276' '00221' '00352' '00141' '00178' '00600' '00550'\n",
      " '02000' '00225' '00210' '00110' '00356' '00045' '00062' '00092' '00174'\n",
      " '00017' '00086' '00454' '00254' '00028' '00263' '00333' '00312' '00290'\n",
      " '00371' '00099' '00252' '00760' '00560' '00130' '00523' '00680' '00163'\n",
      " '00208' '00383' '00330' '00422' '00840' '00432' '00032' '00186' '00303'\n",
      " '00349' '00224' '00369' '00076' '00231' '00309' '00416' '00465' '00256'] A16: ['+' '-']\n",
      "A2: mean: 31.56817109144546 range: 66.5\n",
      "A3: mean: 4.7587246376811585 range: 28.0\n",
      "A8: mean: 2.2234057971014476 range: 28.5\n",
      "A11: mean: 2.4 range: 67\n",
      "A15: mean: 1017.3855072463768 range: 100000\n"
     ]
    }
   ],
   "source": [
    "# Describe the variables: for the categorical variables print the possible categories, for the numeric\n",
    "# variables compute the means and range.\n",
    "print(\"A1:\", pd.unique(credit['A1']), \"A4:\", pd.unique(credit['A4']), \"A5\", pd.unique(credit['A5']),\\\n",
    "      \"A6:\", pd.unique(credit['A6']), \"A7:\", pd.unique(credit['A7']), \"A9:\", pd.unique(credit['A9']),\\\n",
    "      \"A10:\", pd.unique(credit['A10']), \"A12:\", pd.unique(credit['A12']),\\\n",
    "      \"A13:\", pd.unique(credit['A13']), \"A14:\", pd.unique(credit['A14']), \"A16:\", pd.unique(credit['A16']))\n",
    "\n",
    "credit['A2'] = credit['A2'].astype('float')\n",
    "mean_beforeA2 = credit['A2'].mean()\n",
    "credit['A2'] = credit['A2'].fillna(mean_beforeA2)\n",
    "print(\"A2: mean:\", credit['A2'].mean(), \"range:\", credit['A2'].max() - credit['A2'].min())\n",
    "\n",
    "mean_beforeA3 = credit['A3'].mean()\n",
    "credit['A3'] = credit['A3'].replace('?', mean_beforeA3)\n",
    "print(\"A3: mean:\", credit['A3'].mean(), \"range:\", credit['A3'].max() - credit['A3'].min())\n",
    "\n",
    "mean_beforeA8 = credit['A8'].mean()\n",
    "credit['A8'] = credit['A8'].replace('?', mean_beforeA8)\n",
    "print(\"A8: mean:\", credit['A8'].mean(), \"range:\", credit['A8'].max() - credit['A8'].min())\n",
    "\n",
    "mean_beforeA11 = credit['A11'].mean()\n",
    "credit['A11'] = credit['A11'].replace('?', mean_beforeA11)\n",
    "print(\"A11: mean:\", credit['A11'].mean(), \"range:\", credit['A11'].max() - credit['A11'].min())\n",
    "\n",
    "mean_beforeA15 = credit['A15'].mean()\n",
    "credit['A15'] = credit['A15'].replace('?', mean_beforeA15)\n",
    "print(\"A15: mean:\", credit['A15'].mean(), \"range:\", credit['A15'].max() - credit['A15'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I treated `A2` as a float rather than as object because the differing number values doesn't mean as much as calculating mean and range for a variable of numbers. For the numbers marked with `?` with is an NA value, I replaced it with the average of the variable for a more representative calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data into training/testing part.\n",
    "X =  np.stack((credit['A2'].values, credit['A3'].values), axis=1)\n",
    "credit['A16'] = credit['A16'].replace('+', 1)\n",
    "credit['A16'] = credit['A16'].replace('-', 0)\n",
    "y = credit['A16'].values.astype('int')\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple initial LMP predicting A16 being positive. \n",
    "m = slm.LinearRegression().fit(Xtr, ytr)\n",
    "yhat = m.predict(X)\n",
    "yhat = np.where(yhat >= 0.5, 1, yhat) \n",
    "yhat = np.where(yhat < 0.5, 0, yhat) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to conduct a representative crosstab for linear regression, I converted the values inside the yhat array into 1s and 0s, depending on if the values are `>= 0.5` or `< 0.5`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.618840579710145\n"
     ]
    }
   ],
   "source": [
    "# Compute the prediction accuracy on testing data using this model.\n",
    "pd.crosstab(y, yhat)\n",
    "print(\"Accuracy:\", np.mean(y == yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6260869565217392\n"
     ]
    }
   ],
   "source": [
    "# Repeat these two steps with a similar logistic regression model.\n",
    "m_log = slm.LogisticRegression(solver='lbfgs').fit(Xtr, ytr)\n",
    "yhat_log = m_log.predict(X)\n",
    "pd.crosstab(y, yhat_log)\n",
    "print(\"Accuracy:\", np.mean(y == yhat_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Model:\n",
      "Linear Regression Accuracy: 0.7246376811594203\n",
      "Logistic Regression Accuracy: 0.7391304347826086\n",
      "\n",
      "Second Model:\n",
      "Linear Regression Accuracy: 0.8579710144927536\n",
      "Logistic Regression Accuracy: 0.8565217391304348\n"
     ]
    }
   ],
   "source": [
    "# Develop two more complex models adding more variables from the data.\n",
    "# Perform Linear probabliity regression and logistic regression versions of both models. \n",
    "\n",
    "# First Complex Model\n",
    "credit['A10'] = credit['A10'].replace('t', True)\n",
    "credit['A10'] = credit['A10'].replace('f', False)\n",
    "credit['A10'] = credit['A10'].values.astype('int')\n",
    "\n",
    "X1 =  np.stack((credit['A2'].values, credit['A3'].values, credit['A11'].values), axis=1)\n",
    "Xtr, Xte, ytr, yte = train_test_split(X1, y, test_size = 0.2)\n",
    "\n",
    "m1_lin = slm.LinearRegression().fit(Xtr, ytr)\n",
    "yhat1_lin = m1_lin.predict(X1)\n",
    "yhat1_lin = np.where(yhat1_lin >= 0.5, 1, yhat1_lin) \n",
    "yhat1_lin = np.where(yhat1_lin < 0.5, 0, yhat1_lin) \n",
    "crossed_lin1 = pd.crosstab(y, yhat1_lin)\n",
    "print(\"First Model:\")\n",
    "print(\"Linear Regression Accuracy:\", np.mean(y == yhat1_lin))\n",
    "\n",
    "m1_log = slm.LogisticRegression(solver=\"lbfgs\").fit(Xtr, ytr)\n",
    "yhat1_log = m1_log.predict(X1)\n",
    "crossed_log = pd.crosstab(y, yhat1_log)\n",
    "print(\"Logistic Regression Accuracy:\", np.mean(y == yhat1_log))\n",
    "\n",
    "# Second Complex Model\n",
    "credit['A1'] = credit['A1'].fillna('a')\n",
    "credit['A1'] = credit['A1'].replace('a', 0)\n",
    "credit['A1'] = credit['A1'].replace('b', 1)\n",
    "credit['A4'] = credit['A4'].fillna('u')\n",
    "credit['A4'] = (credit.A4 != \"u\").values.astype('int')\n",
    "credit['A13'] = credit['A13'].fillna('g')\n",
    "credit['A13'] = (credit.A13 != \"g\").values.astype('int')\n",
    "credit['A9'] = credit['A9'].replace('t', True)\n",
    "credit['A9'] = credit['A9'].replace('f', False)\n",
    "credit['A9'] = credit['A9'].values.astype('int')\n",
    "credit['A12'] = credit['A12'].replace('t', True)\n",
    "credit['A12'] = credit['A12'].replace('f', False)\n",
    "credit['A12'] = credit['A12'].values.astype('int')\n",
    "\n",
    "X2 =  np.stack((credit['A1'].values, credit['A2'].values, credit['A3'].values, credit['A4'].values,\\\n",
    "                credit['A8'].values, credit['A9'].values, credit['A10'].values, credit['A11'].values,\\\n",
    "                credit['A12'], credit['A15']), axis=1)\n",
    "Xtr, Xte, ytr, yte = train_test_split(X2, y, test_size = 0.2)\n",
    "\n",
    "m2_lin = slm.LinearRegression().fit(Xtr, ytr)\n",
    "yhat2_lin = m2_lin.predict(X2)\n",
    "yhat2_lin = np.where(yhat2_lin >= 0.5, 1, yhat2_lin) \n",
    "yhat2_lin = np.where(yhat2_lin < 0.5, 0, yhat2_lin) \n",
    "crossed_lin2 = pd.crosstab(y, yhat2_lin)\n",
    "print()\n",
    "print(\"Second Model:\")\n",
    "print(\"Linear Regression Accuracy:\", np.mean(y == yhat2_lin))\n",
    "\n",
    "m2_log = slm.LogisticRegression(solver=\"lbfgs\", max_iter=1000).fit(Xtr, ytr)\n",
    "yhat2_log = m2_log.predict(X2)\n",
    "crossed_log2 = pd.crosstab(y, yhat2_log)\n",
    "print(\"Logistic Regression Accuracy:\", np.mean(y == yhat2_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, present my best model (in terms of accuracy on test data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Logistic Regression Model performed better in my case by yielding a higher accuracy value. The best model in regards to test model was my second complex model, by resulting in a linear regression accuracy of 0.8565217391304348 and logistic regression accuracy of 0.8695652173913043. This model performed better because it contained more variables that could potentially be pertinent and good predictors in explaning `A16`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
